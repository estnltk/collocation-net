{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9ee1ab6",
   "metadata": {},
   "source": [
    "# Inter-Annotator Agreement\n",
    "\n",
    "Our aim is to analyse inter-annotator agreement for different subject-verb-object prediction tasks.\n",
    "In these tasks an annotator must judge based on his or her knowledge about the world whether a proposed  subject-verb-object triple is plausible. A subject-verb-object triple is considered plausible when it occurs naturally in the reald world and is not a hypothetical possibility. Of course, such judgements are subjective as different individuals draw different thresholds between practical pausibility and hypothetical possibility.\n",
    "In the following, we analyse agreement between different annotators.  \n",
    "\n",
    "**Sources:**\n",
    "* [statsmodels.stats.inter_rater](https://www.statsmodels.org/stable/_modules/statsmodels/stats/inter_rater.html) \n",
    "* [NLTK: Agreement metrics](https://www.nltk.org/api/nltk.metrics.agreement.html)\n",
    "* [Common pitfalls in statistical analysis: Measures of agreement](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5654219/)\n",
    "* [Agree or Disagree? A Demonstration of An Alternative Statistic to Cohen’s Kappa for Measuring the Extent and Reliability of Agreement between Observers](https://nces.ed.gov/FCSM/pdf/J4_Xie_2013FCSM.pdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c3b60d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pandas import DataFrame\n",
    "from pandas import read_csv\n",
    "from pandas import concat, merge\n",
    "\n",
    "from statsmodels.stats.inter_rater import cohens_kappa\n",
    "\n",
    "from estimators import observed_agreement\n",
    "from estimators import get_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a97bbf",
   "metadata": {},
   "source": [
    "## I. Detection of invalid SVO triples\n",
    "\n",
    "All SVO-triples were generated by sampling sentences from the corpora.\n",
    "This caused two types of errors to be corrected:\n",
    "* incorrect triples due to incorrect syntax tree;\n",
    "* triples where subject is equal to the object.\n",
    "\n",
    "We are going to remove corresponding SVO-prediction tasks corresponding to these sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d45133ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of incorrect sentences: 33 (6.60%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sentence</th>\n",
       "      <th>subject</th>\n",
       "      <th>verb</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Mind ei võlu eriti väljavaade saada järgmiseks...</td>\n",
       "      <td>väljavaade</td>\n",
       "      <td>saama</td>\n",
       "      <td>võlu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Eesti kohta nii hulle arve esile tuua ei saa .</td>\n",
       "      <td>arve</td>\n",
       "      <td>tooma</td>\n",
       "      <td>hull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>Modelliagentuuri MASS juhivad Oleg ja Raul kah...</td>\n",
       "      <td>mass</td>\n",
       "      <td>juhtima</td>\n",
       "      <td>Oleg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>Vähemalt nii on väitnud lepingu lõpetanud Nõmm...</td>\n",
       "      <td>direktor</td>\n",
       "      <td>lõpetama</td>\n",
       "      <td>leping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>Tema neli last oksendasid öö läbi , kui ema ke...</td>\n",
       "      <td>laps</td>\n",
       "      <td>oksendama</td>\n",
       "      <td>öö</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27</td>\n",
       "      <td>Aga sõda ei vallandanud serbia ega bosnia rahv...</td>\n",
       "      <td>sõda</td>\n",
       "      <td>vallandama</td>\n",
       "      <td>rahvas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28</td>\n",
       "      <td>Ent paljuks ei pea suu korrashoiu eest rohkem ...</td>\n",
       "      <td>õpetaja</td>\n",
       "      <td>maksma</td>\n",
       "      <td>suu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30</td>\n",
       "      <td>Kuid miks peab üks inimene justkui Jeesus Kris...</td>\n",
       "      <td>inimene</td>\n",
       "      <td>lunastama</td>\n",
       "      <td>pangandus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>79</td>\n",
       "      <td>“ Vägivald sünnitab vägivalda , ” võtab kokku ...</td>\n",
       "      <td>vägivald</td>\n",
       "      <td>sünnitama</td>\n",
       "      <td>vägivald</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>105</td>\n",
       "      <td>“ Hommikul poole üheksast õhtul poole üheksani...</td>\n",
       "      <td>pool</td>\n",
       "      <td>hoidma</td>\n",
       "      <td>ise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>107</td>\n",
       "      <td>Kui nad seda ei suuda , ei taha ma neid oma bu...</td>\n",
       "      <td>mina</td>\n",
       "      <td>tahtma</td>\n",
       "      <td>buss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>113</td>\n",
       "      <td>Viimased kohalikud valimised võitnud Mahla on ...</td>\n",
       "      <td>valimine</td>\n",
       "      <td>võitma</td>\n",
       "      <td>mahl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>146</td>\n",
       "      <td>Ilumängu vahukoore sisse upub loo ihar ja võik...</td>\n",
       "      <td>sisu</td>\n",
       "      <td>uppuma</td>\n",
       "      <td>loog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>174</td>\n",
       "      <td>“ See katab kooli reaalsed kulud ja midagi jää...</td>\n",
       "      <td>see</td>\n",
       "      <td>katma</td>\n",
       "      <td>kulg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>176</td>\n",
       "      <td>Jõulueelse reklaamikampaania ajal sõlmis Radio...</td>\n",
       "      <td>reklaamikampaania</td>\n",
       "      <td>sõlmima</td>\n",
       "      <td>liitumisleping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>223</td>\n",
       "      <td>Välismaa leheküljed toimetanud Aive Lauriste P...</td>\n",
       "      <td>lehekülg</td>\n",
       "      <td>palkama</td>\n",
       "      <td>turvamees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>250</td>\n",
       "      <td>Publik armastas Mati Nuudet .</td>\n",
       "      <td>Mati</td>\n",
       "      <td>armastama</td>\n",
       "      <td>publik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>261</td>\n",
       "      <td>Lapsepõlve suved veetis Peterburis sündinud Ha...</td>\n",
       "      <td>suvi</td>\n",
       "      <td>veetma</td>\n",
       "      <td>Hans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>287</td>\n",
       "      <td>Mida arvate naljast “ Kaur Kender on Rain Lõhm...</td>\n",
       "      <td>koduloom</td>\n",
       "      <td>arvama</td>\n",
       "      <td>mis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>308</td>\n",
       "      <td>Venemaalt turgu otsivad Eesti tootjad on välje...</td>\n",
       "      <td>tootja</td>\n",
       "      <td>otsima</td>\n",
       "      <td>turg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>334</td>\n",
       "      <td>Kurkse õnnetus paljastas nõrgad kohad Eesti ri...</td>\n",
       "      <td>õnnetus</td>\n",
       "      <td>paljastama</td>\n",
       "      <td>koha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>338</td>\n",
       "      <td>Praegu külastab raamatukogu vähemalt iga kolma...</td>\n",
       "      <td>raamatukogu</td>\n",
       "      <td>külastama</td>\n",
       "      <td>elanik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>364</td>\n",
       "      <td>Olgugi vahepeal aastad lavastaja näole kortse ...</td>\n",
       "      <td>lavastaja</td>\n",
       "      <td>kirjutama</td>\n",
       "      <td>korts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>373</td>\n",
       "      <td>Pulmad , lapse sünd , Oscari võitnud film ja t...</td>\n",
       "      <td>film</td>\n",
       "      <td>võitma</td>\n",
       "      <td>Oscari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>375</td>\n",
       "      <td>Meie mees te valiku kiitsid heaks Rootsi nõust...</td>\n",
       "      <td>sina</td>\n",
       "      <td>kiitma</td>\n",
       "      <td>nõustaja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>379</td>\n",
       "      <td>” Kuid kui naised edasi lunisid , siis Vilja r...</td>\n",
       "      <td>vili</td>\n",
       "      <td>rääkima</td>\n",
       "      <td>pisiasi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>404</td>\n",
       "      <td>Samal ajal valasid õli tulle ja süvendasid inv...</td>\n",
       "      <td>õli</td>\n",
       "      <td>valama</td>\n",
       "      <td>tuli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>405</td>\n",
       "      <td>Tapmiskatse võõra riigi territooriumil paiskas...</td>\n",
       "      <td>suhe</td>\n",
       "      <td>paiskama</td>\n",
       "      <td>kriis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>406</td>\n",
       "      <td>Nemad tekitavad samapalju kahju kui esimesed .</td>\n",
       "      <td>tema</td>\n",
       "      <td>tekitama</td>\n",
       "      <td>kahi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>410</td>\n",
       "      <td>Aga me räägime Andrusega mõlemad ikka iga päev...</td>\n",
       "      <td>mina</td>\n",
       "      <td>rääkima</td>\n",
       "      <td>mõlema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>416</td>\n",
       "      <td>Keegi oleks saanud oma CV-sse punkti kirja , a...</td>\n",
       "      <td>keegi</td>\n",
       "      <td>saama</td>\n",
       "      <td>kiri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>484</td>\n",
       "      <td>Aastal 1989 võttis Rock Summeri kontserdil üks...</td>\n",
       "      <td>mees</td>\n",
       "      <td>võtma</td>\n",
       "      <td>oma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>490</td>\n",
       "      <td>Tuntud ja lugupeetud isa nime varjus tegi ta v...</td>\n",
       "      <td>tema</td>\n",
       "      <td>tegema</td>\n",
       "      <td>kahi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                           sentence  \\\n",
       "0       0  Mind ei võlu eriti väljavaade saada järgmiseks...   \n",
       "1       5     Eesti kohta nii hulle arve esile tuua ei saa .   \n",
       "2      11  Modelliagentuuri MASS juhivad Oleg ja Raul kah...   \n",
       "3      16  Vähemalt nii on väitnud lepingu lõpetanud Nõmm...   \n",
       "4      26  Tema neli last oksendasid öö läbi , kui ema ke...   \n",
       "5      27  Aga sõda ei vallandanud serbia ega bosnia rahv...   \n",
       "6      28  Ent paljuks ei pea suu korrashoiu eest rohkem ...   \n",
       "7      30  Kuid miks peab üks inimene justkui Jeesus Kris...   \n",
       "8      79  “ Vägivald sünnitab vägivalda , ” võtab kokku ...   \n",
       "9     105  “ Hommikul poole üheksast õhtul poole üheksani...   \n",
       "10    107  Kui nad seda ei suuda , ei taha ma neid oma bu...   \n",
       "11    113  Viimased kohalikud valimised võitnud Mahla on ...   \n",
       "12    146  Ilumängu vahukoore sisse upub loo ihar ja võik...   \n",
       "13    174  “ See katab kooli reaalsed kulud ja midagi jää...   \n",
       "14    176  Jõulueelse reklaamikampaania ajal sõlmis Radio...   \n",
       "15    223  Välismaa leheküljed toimetanud Aive Lauriste P...   \n",
       "16    250                      Publik armastas Mati Nuudet .   \n",
       "17    261  Lapsepõlve suved veetis Peterburis sündinud Ha...   \n",
       "18    287  Mida arvate naljast “ Kaur Kender on Rain Lõhm...   \n",
       "19    308  Venemaalt turgu otsivad Eesti tootjad on välje...   \n",
       "20    334  Kurkse õnnetus paljastas nõrgad kohad Eesti ri...   \n",
       "21    338  Praegu külastab raamatukogu vähemalt iga kolma...   \n",
       "22    364  Olgugi vahepeal aastad lavastaja näole kortse ...   \n",
       "23    373  Pulmad , lapse sünd , Oscari võitnud film ja t...   \n",
       "24    375  Meie mees te valiku kiitsid heaks Rootsi nõust...   \n",
       "25    379  ” Kuid kui naised edasi lunisid , siis Vilja r...   \n",
       "26    404  Samal ajal valasid õli tulle ja süvendasid inv...   \n",
       "27    405  Tapmiskatse võõra riigi territooriumil paiskas...   \n",
       "28    406     Nemad tekitavad samapalju kahju kui esimesed .   \n",
       "29    410  Aga me räägime Andrusega mõlemad ikka iga päev...   \n",
       "30    416  Keegi oleks saanud oma CV-sse punkti kirja , a...   \n",
       "31    484  Aastal 1989 võttis Rock Summeri kontserdil üks...   \n",
       "32    490  Tuntud ja lugupeetud isa nime varjus tegi ta v...   \n",
       "\n",
       "              subject        verb          object  \n",
       "0          väljavaade       saama            võlu  \n",
       "1                arve       tooma            hull  \n",
       "2                mass     juhtima            Oleg  \n",
       "3            direktor    lõpetama          leping  \n",
       "4                laps   oksendama              öö  \n",
       "5                sõda  vallandama          rahvas  \n",
       "6             õpetaja      maksma             suu  \n",
       "7             inimene   lunastama       pangandus  \n",
       "8            vägivald   sünnitama        vägivald  \n",
       "9                pool      hoidma             ise  \n",
       "10               mina      tahtma            buss  \n",
       "11           valimine      võitma            mahl  \n",
       "12               sisu      uppuma            loog  \n",
       "13                see       katma            kulg  \n",
       "14  reklaamikampaania     sõlmima  liitumisleping  \n",
       "15           lehekülg     palkama       turvamees  \n",
       "16               Mati   armastama          publik  \n",
       "17               suvi      veetma            Hans  \n",
       "18           koduloom      arvama             mis  \n",
       "19             tootja      otsima            turg  \n",
       "20            õnnetus  paljastama            koha  \n",
       "21        raamatukogu   külastama          elanik  \n",
       "22          lavastaja   kirjutama           korts  \n",
       "23               film      võitma          Oscari  \n",
       "24               sina      kiitma        nõustaja  \n",
       "25               vili     rääkima         pisiasi  \n",
       "26                õli      valama            tuli  \n",
       "27               suhe    paiskama           kriis  \n",
       "28               tema    tekitama            kahi  \n",
       "29               mina     rääkima          mõlema  \n",
       "30              keegi       saama            kiri  \n",
       "31               mees       võtma             oma  \n",
       "32               tema      tegema            kahi  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = read_csv('original_sentences_annotation.csv')\n",
    "assert df.shape == (500, 5), 'The file must contain 500 rows and 5 columns'\n",
    "assert all(df['hinnang'].isin(['yes', 'no'])), 'Incorrect judgements' \n",
    "assert all(df.columns == ['sentence','subject', 'verb', 'object', 'hinnang']), 'Incorrect column names'\n",
    "invalid_tasks = df[(df['hinnang'] == 'no') | (df['subject'] == df['object'])].iloc[:, :4].reset_index()   \n",
    "\n",
    "print(f'Number of incorrect sentences: {len(invalid_tasks)} ({len(invalid_tasks)/len(df)*100 :.2f}%)')\n",
    "display(invalid_tasks)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614f772e",
   "metadata": {},
   "source": [
    "## I. SVO prediction without background\n",
    "\n",
    "In this task, annotators have to predict wether subject-verb-object pair is possible without any background information, i.e., the annotator sees only a SVO-triple of lemmas and must make a binary decision. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8bfd0a",
   "metadata": {},
   "source": [
    "### Agreement between human annotators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92bdf9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation = {}\n",
    "idx_range = range(1, 6)\n",
    "\n",
    "\n",
    "# The first annotator\n",
    "dfs = [read_csv(f'annotator1/svo_100_{i}.csv', index_col=0, encoding='utf-8') for i in idx_range]\n",
    "assert all(df.shape == (200, 4) for df in dfs), 'Each file must contain 200 rows and 4 columns'\n",
    "assert all(all(df.columns == ['subject', 'verb', 'object', 'hindaja1']) for df in dfs), 'Incorrect column names'\n",
    "assert all(all(df['hindaja1'].isin(['no', 'yes'])) for df in dfs), 'Incorrect judgements'\n",
    "\n",
    "annotation[1] = concat(dfs, axis=0).rename(columns={'hindaja1': 'hinnang_1'})\n",
    "\n",
    "\n",
    "# The second annotator\n",
    "dfs = [read_csv(f'annotator2/svo_{i}.csv', index_col=0, encoding='latin1') for i in idx_range]\n",
    "assert all(df.shape == (200, 4) for df in dfs), 'Each file must contain 200 rows and 4 columns'\n",
    "assert all(all(df.columns == ['subject', 'verb', 'object', 'hinnang']) for df in dfs), 'Incorrect column names'\n",
    "assert all(all(df['hinnang'].isin(['no', 'yes'])) for df in dfs), 'Incorrect judgements'\n",
    "\n",
    "annotation[2] = concat(dfs, axis=0).rename(columns={'hinnang': 'hinnang_2'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f4f9be",
   "metadata": {},
   "source": [
    "Amazingly, some SVO-triples occur more than once in the dataset and thus we cannot merge tables based on the SVO columns. Instead, we just need to concatenate assignments as is and check that rows are in the same order in all files. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df5c038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "svo_cols = ['subject', 'verb', 'object']\n",
    "df = concat((annotation[1][svo_cols], annotation[2][svo_cols]), axis=1)\n",
    "assert all(df['subject'].nunique(axis = 1) == 1), 'All subjects must be equal'\n",
    "assert all(df['verb'].nunique(axis = 1) == 1), 'All verbs must be equal'\n",
    "assert all(df['object'].nunique(axis = 1) == 1), 'All objects must be equal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3668c9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = concat([annotation[1], annotation[2]['hinnang_2']], axis=1)\n",
    "assert len(tbl) == len(annotation[1]), 'The number of rows is off'\n",
    "assert all(tbl['hinnang_1'].isin(['no', 'yes'])), 'Some triples are missing form the first table'\n",
    "assert all(tbl['hinnang_2'].isin(['no', 'yes'])), 'Some triples are missing form the second table'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0e6776f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task with incorrect sentences\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>325</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>26</td>\n",
       "      <td>571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      no  yes\n",
       "no   325   78\n",
       "yes   26  571"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed agreement: 89.60%\n",
      "Cohonen kappa:      77.92%\n"
     ]
    }
   ],
   "source": [
    "print('Task with incorrect sentences')\n",
    "\n",
    "confusion_matrix = get_confusion_matrix(tbl, ['hinnang_1', 'hinnang_2'])\n",
    "display(confusion_matrix.rename_axis(None, axis=0).rename_axis(None, axis=1))\n",
    "\n",
    "print(f'Observed agreement: {observed_agreement(confusion_matrix) * 100 :.2f}%')\n",
    "print(f'Cohonen kappa:      {cohens_kappa(confusion_matrix)[\"kappa\"] * 100 :.2f}%') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bbd57ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task without incorrect sentences\n"
     ]
    }
   ],
   "source": [
    "print('Task without incorrect sentences')\n",
    "\n",
    "# To complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e65fa2a",
   "metadata": {},
   "source": [
    "### Agreement between human and svo-prediction\n",
    "\n",
    "TODO: Birgit ole hea ja tekita siia collocation_net-il põhinevad SVO märgendused. \n",
    "Siis me saame arvutada kokkulangevuse erinevate osapoolte ja SVO-algoritmiga\n",
    "Et näida palju teaduslikum võime vaadata kas kappa skoorid on oluliselt erinevad erinevate inimeste omast. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e5ad3d",
   "metadata": {},
   "source": [
    "## II. SVO prediction with background\n",
    "\n",
    "In this task, annotators have to predict wether subject-verb-object pair is possible given the surrounding sentence as context. To avoid priming, SVO-triple is still given as a pair ov subject-object lemmas -- it is not always possible to synthesise subject-object pair in right cases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07f2701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_annotation = {}\n",
    "idx_range = range(1, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05ff47a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first annotator\n",
    "dfs = [read_csv(f'annotator1/svo_100_sentences_{i}.csv', index_col=0, encoding='utf-8').iloc[:, :4] for i in idx_range]\n",
    "assert all(df.shape == (200, 4) for df in dfs), 'Each file must contain 200 rows and 4 columns'\n",
    "assert all(all(df.columns == ['sentence','subject', 'object', 'hinnang']) for df in dfs), 'Incorrect column names'\n",
    "assert all(all(df['hinnang'].isin(['no', 'yes'])) for df in dfs), 'Incorrect judgements'\n",
    "\n",
    "bg_annotation[1] = concat(dfs, axis=0).rename(columns={'hinnang': 'hinnang_1'})\n",
    "\n",
    "# The second annotator\n",
    "dfs = [read_csv(f'annotator2/svo_sentences_{i}.csv', index_col=0, encoding='utf-8') for i in idx_range]\n",
    "\n",
    "# Quick hack to correct data errors\n",
    "dfs[0].loc[26:27, 'hinnang'] = 'no'\n",
    "dfs[0].loc[26:27, 'sentence'] = '***** on laenanud välisturgudelt 800 miljonit ***** , Tallinna Pank 400 miljonit , Ühispank 400 miljonit , Hoiupank 560 miljonit ; sama teed lähevad varsti ka väiksemad pangad .'\n",
    "dfs[0].loc[26:27, 'subject'] = ['Hansapank', 'kroon']\n",
    "dfs[0].loc[26:27, 'object'] = ['kroon', 'Hansapank']\n",
    "dfs[3].loc[120,'hinnang'] = 'yes'\n",
    "\n",
    "# Data validation\n",
    "assert all(df.shape == (200, 4) for df in dfs), 'Each file must contain 200 rows and 4 columns'\n",
    "assert all(all(df.columns == ['sentence', 'subject', 'object', 'hinnang']) for df in dfs), 'Incorrect column names'\n",
    "assert all(all(df['hinnang'].isin(['no', 'yes'])) for df in dfs), 'Incorrect judgements'\n",
    "\n",
    "bg_annotation[2] = concat(dfs, axis=0).rename(columns={'hinnang': 'hinnang_2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "110a7be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "svo_cols = ['sentence', 'subject', 'object']\n",
    "df = concat((bg_annotation[1][svo_cols], bg_annotation[2][svo_cols]), axis=1)\n",
    "assert all(df['sentence'].nunique(axis = 1) == 1), 'All sentences must be equal'\n",
    "assert all(df['subject'].nunique(axis = 1) == 1), 'All verbs must be equal'\n",
    "assert all(df['object'].nunique(axis = 1) == 1), 'All objects must be equal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9372cb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = concat([bg_annotation[1], bg_annotation[2]['hinnang_2']], axis=1)\n",
    "assert len(tbl) == len(annotation[1]), 'The number of rows is off'\n",
    "assert all(tbl['hinnang_1'].isin(['no', 'yes'])), 'Some triples are missing form the first table'\n",
    "assert all(tbl['hinnang_2'].isin(['no', 'yes'])), 'Some triples are missing form the second table'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab786de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task with incorrect sentences\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>474</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>27</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      no  yes\n",
       "no   474   34\n",
       "yes   27  465"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed agreement: 93.90%\n",
      "Cohonen kappa:      87.80%\n"
     ]
    }
   ],
   "source": [
    "print('Task with incorrect sentences')\n",
    "confusion_matrix = get_confusion_matrix(tbl, ['hinnang_1', 'hinnang_2'])\n",
    "display(confusion_matrix.rename_axis(None, axis=0).rename_axis(None, axis=1))\n",
    "\n",
    "print(f'Observed agreement: {observed_agreement(confusion_matrix) * 100 :.2f}%')\n",
    "print(f'Cohonen kappa:      {cohens_kappa(confusion_matrix)[\"kappa\"] * 100 :.2f}%') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bba5939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task without incorrect sentences\n"
     ]
    }
   ],
   "source": [
    "print('Task without incorrect sentences')\n",
    "\n",
    "# To complete"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
